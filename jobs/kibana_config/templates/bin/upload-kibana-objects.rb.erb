#!/var/vcap/packages/ruby-2.3/bin/ruby
# `set -x`
<%
  elasticsearch_url = ""
  if_p("elasticsearch_config.elasticsearch.endpoint") do |endpoint|
    elasticsearch_url = endpoint
  end.else do
    elasticsearch_host = nil
    if_link("elasticsearch") { |elasticsearch_link| elasticsearch_host = elasticsearch_link.instances.first.address }
    unless elasticsearch_host
      elasticsearch_host = p("elasticsearch_config.elasticsearch.host")
    end
    elasticsearch_port = nil
    if_link("elasticsearch") { |elasticsearch_link| elasticsearch_port = elasticsearch_link.p("elasticsearch.port") }
    unless elasticsearch_port
      elasticsearch_port = p("elasticsearch_config.elasticsearch.port")
    end
    proto = p("elasticsearch_config.elasticsearch.proto", "http")
    elasticsearch_url = "#{proto}://#{elasticsearch_host}:#{elasticsearch_port}"
  end
  
  elasticsearch_auth = ""
  if_p("elasticsearch_config.elasticsearch.auth") do |auth|
    elasticsearch_auth = "#{auth}"
  end.else do
    if_p("elasticsearch_config.elasticsearch.user") do |user|
      elasticsearch_auth =  "#{user}:#{p('elasticsearch_config.elasticsearch.password', '')}"
    end
  end
%>

require 'json'
require 'logger'
$logger = Logger.new("/var/vcap/sys/log/kibana_config/upload-kibana-objects.stdout.log")


def log_status(message, is_error = false)
  if is_error
    $logger.error(message)
  else
    $logger.info(message)
  end
  puts message
end


def render_upsert_queries(type, pattern)
  combined = ""
  Dir.glob(pattern).each do |data_file|
    file_content = File.read(data_file).strip
    if file_content.empty?
      # skip empty file
      $logger.warn("SKIP file (empty content) '#{data_file}'")
      next
    end
    begin
      parsed_json = JSON.parse(file_content)
      if 'index-pattern' == type
        # index-pattern usually contains '*' which is special character and can't be used in file name
        # so we set its 'id' from 'title' field instead
        id = parsed_json["title"]
      else
        id = File.basename(data_file, ".json")
      end
      combined += "{\"delete\":{\"_index\":\".kibana\",\"_type\":\"doc\",\"_id\":\"#{id}\"}}\n"
      combined += "{\"index\":{\"_index\":\".kibana\",\"_type\":\"doc\",\"_id\":\"#{id}\"}}\n"
      combined += "#{parsed_json.to_json}\n"
      log_status("#{data_file}")
    rescue StandardError => err
      # skip
      log_status("SKIP file (error in processing) '#{data_file}': #{err.message}", true)
      next
    end
  end
  combined
end


def process_bulk_query_result(result)
  # parse result
  begin
    result_json = JSON.parse(result)
  rescue StandardError => err
    $logger.warn("Failed to process result")
    return result # return the whole result as a fallback for failed result parsing
  end

  # check each result
  statuses_to_print = []
  result_json["items"].each do |item|
    item_result = item["delete"]
    is_delete_item = !item_result.nil?
    if !is_delete_item
      item_result = item["index"]
    end
    if item_result.nil?
      statuses_to_print << item
      next
    end

    begin
      item_status = item_result["status"]
    ensure
      # collect error statuses - those that
      # 1) >= 400 (except DELETEs with 404)
      # 2) undefined
      if !item_status.nil? and item_status.to_i >= 400 and !(item_status == 404 and is_delete_item) or item_status.nil?
        statuses_to_print << item
      end
    end
  end

  if statuses_to_print.empty? and result_json["errors"] != true
    status_str = "Success!"
  else
    status_str = "Failed with errors: " + statuses_to_print.to_json
  end

  status_str
end



### Upload generated objects

log_status("* Upload Kibana objects from job defaults. Start processing data to upload: ")
upload_data = ""
<% p("kibana_config.upload_patterns").each do |pattern| %>
upload_data += render_upsert_queries("<%= pattern.fetch("type") %>", "<%= pattern.fetch("pattern") %>")
<% end %>
$logger.info("* Defaults data to upload:\n#{upload_data}")

$logger.info("* Uploading data to ES ...")
result = `curl -H 'Content-Type: application/json' <%= elasticsearch_auth.to_s.empty? ? "" : "-u #{elasticsearch_auth}" %> <%= elasticsearch_url %>/_bulk -d '#{upload_data.to_s}'`
$logger.info("* Raw result of uploading defaults: #{result}")

puts("* Result of uploading defaults: #{process_bulk_query_result(result)}")


### Upload specified Kibana objects

log_status("* Upload Kibana objects from specified data files: ")
<% p("kibana_config.upload_data_files").each do |object| %>
log_status("Uploading '<%= object %>' ...")
result = `cat <%= object %> | curl -H 'Content-Type: application/json' <%= elasticsearch_auth.to_s.empty? ? "" : "-u #{elasticsearch_auth}" %> <%= elasticsearch_url %>/_bulk --data-binary @-`
$logger.info("* Raw result of uploading '<%= object %>': #{result}")
puts("= Result of uploading '<%= object %>': #{process_bulk_query_result(result)}"
<% end %>

