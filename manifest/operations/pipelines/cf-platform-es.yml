- type: replace
  path: /instance_groups/name=logstash/properties/logstash/conf?/xpack.management.pipeline.id?/-
  value:
    "cf-platform-es"

- type: replace
  path: /instance_groups/name=logstash/properties/logstash/env?/DST_HOSTS?
  value:
    "((es-host))"

- type: replace
  path: /instance_groups/name=logstash/properties/logstash/env/ES_INDEX_PREFIX?
  value:
    "((es-index_prefix))"

- type: replace
  path: /instance_groups/name=logstash/properties/logstash/env/CF_API?
  value:
    "((cf-api))"

- type: replace
  path: /instance_groups/name=logstash/properties/logstash/env/SOURCE_ENV?
  value:
    "((source-env))"

- type: replace
  path: /instance_groups/name=logstash/properties/logstash/env/SOURCE_PLATFORM?
  value:
    "((source-platform))"

- type: replace
  path: /instance_groups/name=logstash/properties/logstash/pipelines?
  value:
    - name: cf-platform-es
      config:
        filter-00-prefiltering: |
          ##-------------
          # Pre filtering
          ##-------------
          
          filter {
              mutate {
                  # Replace the unicode empty character \u0000 with ""
                  gsub => [ "message", '\u0000', ""]
          
                  # Trim excess whitespace
                  strip => [ "message" ]
              }
          
              # Drop empty useless logs
              if [message] =~ /^\s*$/ or [message] =~ /^#.*$/ {
                  drop { }
              }
          
              mutate {
                  rename => { "message" => "@message" }
          
                  # Add tags to track which job processed this event
                  add_field => {
                          "[@parser][job]" => "${JOB_FULL_AZ_DEPLOYMENT}"
                          "[@parser][instance]" => "${INSTANCE_ID}"
                          "[@parser][az]" => "${JOB_AZ}"
                          "[@parser][name]" => "${JOB_NAME}"
                          "[@parser][index]" => "${JOB_INDEX}"
                          "[@parser][deployment]" => "${DEPLOYMENT_NAME}"
                          "[@parser][lb-host]" => "%{host}"
                          "[@parser][lb-port]" => "%{port}"
                  }
          
                  # When behind LB, this is always the IP of the haproxy, not the IP of the actual host sending the data.
                  # Remove it to avoid confusion
                  remove_field => [ "host", "port" ]
              }
          }
        filter-10-syslog_rfc5424_parsing: |
          ##------------------------
          # standard rfc5424 parsing
          ##------------------------
          
          # NOTE: All parsed data should include @message, @level and @source.component.
          # Otherwise these fields are set from syslog_ fields in teardown script afterwards.
          
          filter {
              if ([@input] == "syslog") {
              grok {
                  match => { "@message" => "%{POSINT:syslog_code} %{SYSLOG5424LINE}" }
                  add_tag => [ "syslog-5424" ]
                  add_field => {
                          "@type" => "LogMessage"
                          "@raw" => "%{@message}"
                  }
                  tag_on_failure => ["fail/syslog-5424/grok"]
              }
          
              #                "@level" => "NONE"
          
              syslog_pri {
                  syslog_pri_field_name => "syslog5424_pri"
              }
          
              date {
                  match => [ "syslog5424_ts", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601" ]
                  timezone => "UTC"
                  remove_field => "syslog5424_ts"
              }
          
              mutate {
                  # '@message' should contain the remaining unparsed text
                  rename => { "syslog5424_msg" => "@message" }
              }
          
          
              # Extract instance metadata from structured data
              # grok {
              #     match => { "syslog5424_host" => "(?<org>[a-zA-Z0-9_-]+)\.(?<space>[a-zA-Z0-9_-]+)\.(?<app>[a-zA-Z0-9_-]+)" }
              #     tag_on_failure => [ "fail/syslog-5424/cf/grok" ]
              #     add_tag => [ "cf" ]
              # }
              # if !("fail/syslog-5424/cf/grok" in [tags]) {
              #     mutate {
              #         rename => {
              #             "org" => "[@cf][org]"
              #             "space" => "[@cf][space]"
              #             "app" => "[@cf][app]"
              #         }
              #         add_field => {
              #             "[@cf][app_id]" => "%{syslog5424_app}"
              #             "[@cf][api]" => "${CF_API:cf}"
              #         }
              #     }
              # }
          
          
              # Extract instance index from proc
              # grok {
              #     match => { "syslog5424_proc" => "\[%{DATA:[@metadata][app_source]}\]" }
              #     tag_on_failure => [ "fail/syslog-5424/proc/grok" ]
              # }
              # if !("fail/syslog-5424/proc/grok" in [tags]) {
              #     mutate {
              #         # split the field on /
              #         split => { "[@metadata][app_source]" => "/" }
              #         # save the last element of the array as the app_source.
              #         add_field => {
              #             "[@source][host]" => "%{syslog5424_host}"
              #             "[@source][type]" => "%{[@metadata][app_source][0]}"
              #             "[@source][subtype]" => "none"
              #             "[@source][src]" => "unknown"
              #             "[@source][component]" => "${SOURCE_COMPONENT:LogMessage}"
              #             "[@source][platform]" => "${SOURCE_PLATFORM:cf}"
              #             "[@source][env]" => "${SOURCE_ENV:cf}"
              #             "[@source][instance]" => "%{[@metadata][app_source][-1]}"
              #             "[@source][shipper]" => "${SOURCE_SHIPPER:syslog}"
          
              #             "[@shipper][proto]" => "%{@input}"
              #             "[@shipper][code]" => "%{syslog_code}"
              #             "[@shipper][version]" => "%{syslog5424_ver}"
              #             "[@shipper][facility]" => "%{syslog_facility_code}"
              #             "[@shipper][priority]" => "%{syslog5424_pri}"
              #             "[@shipper][severity]" => "%{syslog_severity_code}"
              #             "[@shipper][name]" => "${SOURCE_SHIPPER:syslog}"
              #             "[@shipper][type]" => "%{[@metadata][app_source]}"
              #             "[@shipper][host]" => "%{[syslog5424_host]}"
          
              #             "@generator" => "%{[@metadata][app_source][0]}"
              #             "@instance" => "%{[@metadata][app_source][-1]}"
              #         }
              #     }
              #     # ruby {
              #     #     code => 'if event.get("[@metadata][app_source]").length > 2 then event.set("[@source][subtype]", event.get("[@metadata][app_source][1]")) end'
              #     # }
              #     if [syslog5424_pri] == "14" {
              #         mutate {
              #             replace => { "[@source][src]" => "stdout" }
              #             add_tag => [ "stdout" ]
              #         }
              #     } else if [syslog5424_pri] == "11" {
              #         mutate {
              #             replace => { "[@source][src]" => "stderr" }
              #             add_tag => [ "stderr" ]
              #         }
              #     }
              #     mutate {
              #         convert => {
              #             "[@source][instance]" => "integer"
              #             "@instance" => "integer"
              #         }
              #         lowercase => [ "[@source][type]", "[@source][subtype]", "[@source][component]" ]
              #         split => { "[@shipper][type]" => "," }
              #         convert => {
              #             "[@shipper][version]" => "integer"
              #             "[@shipper][facility]" => "integer"
              #             "[@shipper][code]" => "integer"
              #             "[@shipper][priority]" => "integer"
              #             "[@shipper][severity]" => "integer"
              #         }
              #         remove_field => [ "syslog5424_ver", "syslog5424_pri", "syslog5424_proc", "syslog5424_app", "syslog5424_host", "syslog_code" ]
              #     }
              # }
            }
          }
        filter-20-set-metadata-index: |
          ##---------
          # Set index
          ##---------
          
          # @index_type stores type of index: app/platform
          # [@metadata][index] stores full index prefix (for app logs additionally includes org and space name)
          
          filter {
              # by default logs go to 'platform'
              mutate {
                  add_field => { "@index_type" => "platform" }
                  # add_field => { "[@metadata][index]" => "%{@index_type}-%{[@source][deployment]}" }
                  lowercase => [ "[@metadata][index]" ]
              }
          }
          
        filter-62-platform_uaa_parsing: |
          ##-------------------------
          # Uaa conf. Parses uaa logs
          ##-------------------------
          
          # filter {
          #     if [@source][component] == "vcap.uaa" {
          #         mutate {
          #           # remove vcap. prefix
          #           replace => { "[@source][component]" => "uaa" }
          #           replace => { "@type" => "uaa" }
          #           add_tag => "uaa"
          #         }
          #         grok {
          #           match => { "@message" => "\[%{TIMESTAMP_ISO8601:[uaa][timestamp]}\]%{SPACE}uaa%{SPACE}-%{SPACE}%{NUMBER:[uaa][pid]:int}%{SPACE}\[%{DATA:[uaa][thread]}\]%{SPACE}....%{SPACE}%{LOGLEVEL:@level}%{SPACE}---%{SPACE}%{DATA:[uaa][log_category]}:%{SPACE}%{GREEDYDATA:@message}"}
          #           overwrite => ["@message", "@level"] # @message, @level
          #           tag_on_failure => "fail/cloudfoundry/platform-uaa/grok"
          #         }
          #         if [uaa][log_category] == "Audit" {
          #             mutate {
          #               replace => { "@type" => "uaa-audit" }
          #               add_tag => "audit"
          #             }
          #             # ---- Additional parsing: Audit events
          #             grok {
          #               match => { "@message" => "(?<uaa_audit_message>(%{WORD:[uaa][audit][type]}%{SPACE}\('%{DATA:[uaa][audit][data]}'\))):%{SPACE}principal=%{DATA:[uaa][audit][principal]},%{SPACE}origin=\[%{DATA:[uaa][audit][origin]}\],%{SPACE}identityZoneId=\[%{DATA:[uaa][audit][identity_zone_id]}\]"}
          #               tag_on_failure => "fail/cloudfoundry/platform-uaa/audit/grok"
          #             }
          #             if !("fail/cloudfoundry/platform-uaa/audit/grok" in [tags]) {
          #                 # Audit @message
          #                 mutate {
          #                   rename => { "uaa_audit_message" => "@message" }
          #                 }
          #                 # extract audit_event_remote_address and geoip it
          #                 if "PrincipalAuthenticationFailure" == [uaa][audit][type] {
          #                     mutate {
          #                       add_field => { "[uaa][audit][remote_address]" => "%{[uaa][audit][origin]}" }
          #                     }
          #                 }
          #                 if [uaa][audit][origin] =~ /remoteAddress=/ {
          #                     grok {
          #                       match => { "[uaa][audit][origin]" => "remoteAddress=%{IP:[uaa][audit][remote_address]}" }
          #                     }
          #                 }
          #                 if [uaa][audit][remote_address] {
          #                    geoip {
          #                      source => "[uaa][audit][remote_address]"
          #                    }
          #                 }
          #                 # split origin
          #                 mutate {
          #                   split =>  { "[uaa][audit][origin]" => ", " }
          #                 }
          #             }
          #         }
          #     }
          # }
          
        filter-63-platform_vcap_and_json_parsing: |
          ##------------------------------------------
          # Vcap conf. Parses vcap* logs. (after UAA!)
          ##------------------------------------------
          
          filter {
                # Parse Cloud Foundry logs
                if [@message] =~ /^\s*{".*}\s*$/ { # looks like JSON
                    # parse JSON message
                    json {
                      source => "@message"
                      target => "parsed_json_field"
                      remove_field => [ "@message" ]
                      add_field => { "parsed_json_field_name" => "%{[@source][component]}"}
                    }
                    if "_jsonparsefailure" in [tags] {
                        # Amend the failure tag to match our fail/${addon}/${filter}/${detail} standard
                        mutate {
                          add_tag => ["fail/cloudfoundry/platform-vcap/json"]
                          remove_tag => ["_jsonparsefailure"]
                        }
                    } else {
                        mutate {
                          rename => { "[parsed_json_field][message]" => "@message" } # @message
                        }
                        # @level
                        translate {
                          field => "[parsed_json_field][log_level]"
                          dictionary => [ "0", "DEBUG", "1", "INFO", "2", "ERROR", "3", "FATAL" ]
                          destination => "@level"
                          override => true
                          fallback => "%{[parsed_json_field][log_level]}"
                          remove_field => "[parsed_json_field][log_level]"
                        }
                    }
              }
          }
          
        filter-90-set_syslog_level: |
          ##-------------------
          # define syslog level
          ##-------------------
          
          # Apply default settings for mandatory fields (if not set)
          
          filter {
              # set syslog @level (if @level is not set yet)
              if ![@level] and [syslog_severity_code] {
                  if [syslog_severity_code] <= 3 {                      # 0-Emergency, 1-Alert, 2-Critical, 3-Error
                      mutate {
                          add_field => { "@level" => "ERROR" }
                      }
                  } else if [syslog_severity_code] <= 5 {               # 4-Warning, 5-Notice
                      mutate {
                          add_field => { "@level" => "WARN" }
                      }
                  } else if [syslog_severity_code] == 6 {               # 6-Informational
                      mutate {
                          add_field => { "@level" => "INFO" }
                      }
                  } else if [syslog_severity_code] == 7 {               # 7-Debug
                      mutate {
                          add_field => { "@level" => "DEBUG" }
                      }
                  }
              }
          
              mutate {
                  uppercase => [ "@level" ]
              }
          }
          
        filter-91-rework_fields: |
          # ##-------------
          # # Rework fields
          # ##-------------
          
          # filter{
          #     if [@source][job] and [@source][index] {
          #         mutate {
          #             add_field => { "[@source][vm]" => "%{[@source][job]}/%{[@source][index]}" }
          #         }
          #     }
          
          #     if ![@source][host] {
          #         mutate { rename => { "[host]" => "[@source][host]" } }
          #     }
          
          #     # Downcase [parsed_json_field_name] and replace special characters with '_')..
          #     # .. and rename dynamic [parsed_json_field] field to this calculated name.
          
          #     if [parsed_json_field] and [parsed_json_field_name] {
          #         mutate {
          #             lowercase => [ "parsed_json_field_name" ]
          #             gsub => [ "parsed_json_field_name", "[\s/\\?#-\.]", "_" ]
          #         }
          #         mutate {
          #             rename => { "parsed_json_field" => "%{parsed_json_field_name}" }
          #         }
          #     }
          
          #     mutate {
          #         remove_field => [ "parsed_json_field_name" ]
          #     }
          # }
          
        filter-99-cleanup: |
          ##--------------------------
          # Cleanup unnecessary fields
          ##--------------------------
          
          # filter {
          #     mutate {
          #         # Remove syslog_ fields
          #         remove_field => "syslog5424_pri"
          #         remove_field => "syslog5424_ts"
          #         remove_field => "syslog5424_host"
          #         remove_field => "syslog5424_ver"
          #         remove_field => "syslog5424_app"
          #         remove_field => "syslog5424_proc"
          #         remove_field => "syslog_sd_params"
          #         remove_field => "syslog_facility"
          #         remove_field => "syslog_facility_code"
          #         remove_field => "syslog_severity"
          #         remove_field => "syslog_severity_code"
          
          #         # Cleanup
          #         remove_field => "@version"
          #         remove_field => "host"
          #         remove_field => "port"
          #         remove_field => "_logstash_input"
          #     }
          # }
          
          
        input-10-syslog: |
          input {
              tcp {
                add_field => [ "@input", "syslog" ]
                id => "input-syslog/${JOB_FULL_AZ_DEPLOYMENT}"
                port => "5514"
              }
              #syslog {
              #    port => 5514
              #    use_labels => true
              #    type => "syslog"
              #    tags => []
              #    add_field => { "_index_name" => "syslog" }
              #}
          }
          
          
        output-10-es: |
          output {
            elasticsearch {
              # DS_HOSTS is default from elasticsearch_master property
              hosts => [ "${DST_HOSTS}" ]
              user => "${ES_USER}"
              password => "${ES_PASSWORD}"
              sniffing => false
              index => "${ES_INDEX_PREFIX}-%{+YYYY.MM.dd}"
              http_compression => true
              manage_template => false
              id => "output-es/${JOB_FULL_AZ_DEPLOYMENT}"
            }
            # stdout { codec => rubydebug }
          }
